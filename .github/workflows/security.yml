name: Security Scanning & Vulnerability Assessment

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run security scans daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Type of security scan'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'sast'
          - 'dependency'
          - 'secrets'
          - 'container'
          - 'license'

env:
  PYTHON_VERSION: '3.11'

jobs:
  # Static Application Security Testing (SAST)
  sast-scan:
    name: SAST Security Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'all' || github.event.inputs.scan_type == 'sast' || github.event.inputs.scan_type == ''
    permissions:
      security-events: write
      actions: read
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          uv pip install bandit[toml] safety semgrep dlint

      - name: Run Bandit SAST scan
        run: |
          uv run bandit -r src/ \
            -f json \
            -o bandit-report.json \
            --severity-level medium \
            --confidence-level medium

          # Also generate human-readable report
          uv run bandit -r src/ \
            -f txt \
            -o bandit-report.txt \
            --severity-level medium \
            --confidence-level medium
        continue-on-error: true

      - name: Run Semgrep scan
        run: |
          # Install semgrep rules
          python -m pip install semgrep

          # Run semgrep with multiple rulesets
          semgrep --config=auto \
            --json \
            --output=semgrep-report.json \
            src/ || true

          # Run with specific Python security rules
          semgrep --config=p/python \
            --json \
            --output=semgrep-python.json \
            src/ || true

      - name: Run dlint (Django security linter)
        run: |
          uv run dlint src/ > dlint-report.txt || true

      - name: Process SAST results
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          # Process Bandit results
          high_severity_issues = 0
          if Path('bandit-report.json').exists():
              with open('bandit-report.json') as f:
                  bandit_data = json.load(f)

              high_severity_issues = len([
                  issue for issue in bandit_data.get('results', [])
                  if issue.get('issue_severity') == 'HIGH'
              ])

              print(f'Bandit found {len(bandit_data.get(\"results\", []))} total issues')
              print(f'High severity issues: {high_severity_issues}')

          # Process Semgrep results
          semgrep_issues = 0
          if Path('semgrep-report.json').exists():
              with open('semgrep-report.json') as f:
                  semgrep_data = json.load(f)

              semgrep_issues = len(semgrep_data.get('results', []))
              print(f'Semgrep found {semgrep_issues} issues')

          # Create summary
          with open('sast-summary.txt', 'w') as f:
              f.write(f'SAST Security Scan Summary\n')
              f.write(f'==========================\n')
              f.write(f'Bandit issues: {len(bandit_data.get(\"results\", []))}\n')
              f.write(f'High severity: {high_severity_issues}\n')
              f.write(f'Semgrep issues: {semgrep_issues}\n')

              if high_severity_issues > 0:
                  f.write(f'\\nCRITICAL: {high_severity_issues} high severity security issues found!\n')
                  sys.exit(1)
          "

      - name: Upload SAST scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sast-scan-results
          path: |
            bandit-report.json
            bandit-report.txt
            semgrep-report.json
            semgrep-python.json
            dlint-report.txt
            sast-summary.txt

      - name: Upload Bandit results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: bandit-sarif.json
        continue-on-error: true

  # Dependency vulnerability scanning
  dependency-scan:
    name: Dependency Vulnerability Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'all' || github.event.inputs.scan_type == 'dependency' || github.event.inputs.scan_type == ''
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          uv pip install safety pip-audit cyclonedx-bom

      - name: Generate Software Bill of Materials (SBOM)
        run: |
          # Generate SBOM for transparency
          uv pip freeze > requirements-current.txt
          cyclonedx-py -r requirements-current.txt -o sbom.json

      - name: Run Safety scan
        run: |
          # Check for known security vulnerabilities
          uv run safety check \
            --json \
            --output safety-report.json \
            --continue-on-error || true

          # Generate human-readable report
          uv run safety check \
            --output safety-report.txt || true

      - name: Run pip-audit scan
        run: |
          # Alternative dependency scanner
          uv run pip-audit \
            --format=json \
            --output=pip-audit-report.json \
            --requirement=requirements-current.txt || true

      - name: Check for outdated dependencies
        run: |
          # Check for outdated packages that might have security updates
          uv pip list --outdated --format=json > outdated-packages.json || true

      - name: Analyze dependency vulnerabilities
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          critical_vulns = 0
          high_vulns = 0
          total_vulns = 0

          # Process Safety results
          if Path('safety-report.json').exists():
              with open('safety-report.json') as f:
                  safety_data = json.load(f)

              for vuln in safety_data:
                  severity = vuln.get('severity', 'unknown').lower()
                  if severity == 'critical':
                      critical_vulns += 1
                  elif severity == 'high':
                      high_vulns += 1
                  total_vulns += 1

          # Process pip-audit results
          pip_audit_vulns = 0
          if Path('pip-audit-report.json').exists():
              with open('pip-audit-report.json') as f:
                  pip_audit_data = json.load(f)
              pip_audit_vulns = len(pip_audit_data.get('vulnerabilities', []))

          # Check outdated packages
          outdated_count = 0
          if Path('outdated-packages.json').exists():
              with open('outdated-packages.json') as f:
                  outdated_data = json.load(f)
              outdated_count = len(outdated_data)

          # Create summary
          with open('dependency-summary.txt', 'w') as f:
              f.write(f'Dependency Vulnerability Scan Summary\n')
              f.write(f'====================================\n')
              f.write(f'Total vulnerabilities (Safety): {total_vulns}\n')
              f.write(f'Critical vulnerabilities: {critical_vulns}\n')
              f.write(f'High severity vulnerabilities: {high_vulns}\n')
              f.write(f'Additional vulnerabilities (pip-audit): {pip_audit_vulns}\n')
              f.write(f'Outdated packages: {outdated_count}\n')

              if critical_vulns > 0:
                  f.write(f'\\nCRITICAL: {critical_vulns} critical vulnerabilities found!\n')
                  sys.exit(1)
              elif high_vulns > 5:  # Threshold for high vulnerabilities
                  f.write(f'\\nWARNING: {high_vulns} high severity vulnerabilities found!\n')
          "

      - name: Upload dependency scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dependency-scan-results
          path: |
            safety-report.json
            safety-report.txt
            pip-audit-report.json
            outdated-packages.json
            sbom.json
            dependency-summary.txt

  # Secrets scanning
  secrets-scan:
    name: Secrets Detection
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'all' || github.event.inputs.scan_type == 'secrets' || github.event.inputs.scan_type == ''
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install secrets detection tools
        run: |
          # Install TruffleHog for secrets detection
          curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin

          # Install gitleaks
          wget -O gitleaks.tar.gz https://github.com/zricethezav/gitleaks/releases/download/v8.18.0/gitleaks_8.18.0_linux_x64.tar.gz
          tar -xzf gitleaks.tar.gz
          sudo mv gitleaks /usr/local/bin/

      - name: Run TruffleHog secrets scan
        run: |
          trufflehog git file://. \
            --json \
            --output=trufflehog-report.json \
            --no-update || true

      - name: Run Gitleaks scan
        run: |
          gitleaks detect \
            --source . \
            --report-format json \
            --report-path gitleaks-report.json \
            --verbose || true

      - name: Analyze secrets scan results
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          secrets_found = 0
          high_confidence_secrets = 0

          # Process TruffleHog results
          if Path('trufflehog-report.json').exists():
              with open('trufflehog-report.json') as f:
                  for line in f:
                      try:
                          result = json.loads(line)
                          if result.get('verified'):
                              high_confidence_secrets += 1
                          secrets_found += 1
                      except json.JSONDecodeError:
                          continue

          # Process Gitleaks results
          gitleaks_secrets = 0
          if Path('gitleaks-report.json').exists():
              with open('gitleaks-report.json') as f:
                  gitleaks_data = json.load(f)
              gitleaks_secrets = len(gitleaks_data)

          # Create summary
          with open('secrets-summary.txt', 'w') as f:
              f.write(f'Secrets Detection Summary\n')
              f.write(f'========================\n')
              f.write(f'Potential secrets (TruffleHog): {secrets_found}\n')
              f.write(f'High confidence secrets: {high_confidence_secrets}\n')
              f.write(f'Secrets detected (Gitleaks): {gitleaks_secrets}\n')

              if high_confidence_secrets > 0:
                  f.write(f'\\nCRITICAL: {high_confidence_secrets} verified secrets found!\n')
                  sys.exit(1)
              elif secrets_found > 0:
                  f.write(f'\\nWARNING: {secrets_found} potential secrets detected!\n')
          "

      - name: Upload secrets scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: secrets-scan-results
          path: |
            trufflehog-report.json
            gitleaks-report.json
            secrets-summary.txt

  # Container security scanning
  container-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'all' || github.event.inputs.scan_type == 'container' || github.event.inputs.scan_type == ''
    steps:
      - uses: actions/checkout@v4

      - name: Build Docker image for scanning
        run: |
          # Create a minimal Dockerfile for scanning if it doesn't exist
          if [ ! -f "Dockerfile" ]; then
            cat > Dockerfile << EOF
          FROM python:3.11-slim

          WORKDIR /app
          COPY pyproject.toml uv.lock ./

          RUN pip install uv
          RUN uv sync --frozen --no-dev

          COPY src/ ./src/

          CMD ["python", "-m", "digitalmodel"]
          EOF
          fi

          docker build -t digitalmodel:security-scan .

      - name: Run Trivy container scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'digitalmodel:security-scan'
          format: 'sarif'
          output: 'trivy-container-results.sarif'

      - name: Run Trivy filesystem scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'json'
          output: 'trivy-fs-results.json'

      - name: Analyze container vulnerabilities
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          critical_vulns = 0
          high_vulns = 0
          total_vulns = 0

          # Process Trivy filesystem results
          if Path('trivy-fs-results.json').exists():
              with open('trivy-fs-results.json') as f:
                  trivy_data = json.load(f)

              for result in trivy_data.get('Results', []):
                  for vuln in result.get('Vulnerabilities', []):
                      severity = vuln.get('Severity', 'UNKNOWN')
                      if severity == 'CRITICAL':
                          critical_vulns += 1
                      elif severity == 'HIGH':
                          high_vulns += 1
                      total_vulns += 1

          # Create summary
          with open('container-summary.txt', 'w') as f:
              f.write(f'Container Security Scan Summary\n')
              f.write(f'===============================\n')
              f.write(f'Total vulnerabilities: {total_vulns}\n')
              f.write(f'Critical vulnerabilities: {critical_vulns}\n')
              f.write(f'High severity vulnerabilities: {high_vulns}\n')

              if critical_vulns > 0:
                  f.write(f'\\nCRITICAL: {critical_vulns} critical vulnerabilities found in container!\n')
          "

      - name: Upload container scan results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: trivy-container-results.sarif

      - name: Upload container scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: container-scan-results
          path: |
            trivy-container-results.sarif
            trivy-fs-results.json
            container-summary.txt

  # License compliance scanning
  license-scan:
    name: License Compliance Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'all' || github.event.inputs.scan_type == 'license' || github.event.inputs.scan_type == ''
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install license checking tools
        run: |
          uv pip install pip-licenses licensecheck

      - name: Generate license report
        run: |
          # Generate detailed license information
          uv run pip-licenses \
            --format=json \
            --output-file=licenses.json \
            --with-urls \
            --with-description

          # Generate summary format
          uv run pip-licenses \
            --format=plain \
            --output-file=licenses.txt

      - name: Check for license compliance
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          # Define prohibited licenses
          prohibited_licenses = [
              'GPL-3.0',
              'AGPL-3.0',
              'SSPL-1.0',
              'EUPL-1.2'
          ]

          # Define licenses requiring review
          review_required = [
              'GPL-2.0',
              'LGPL-2.1',
              'LGPL-3.0',
              'EUPL-1.1'
          ]

          violations = []
          review_needed = []
          unknown_licenses = []

          if Path('licenses.json').exists():
              with open('licenses.json') as f:
                  licenses_data = json.load(f)

              for pkg in licenses_data:
                  license_name = pkg.get('License', 'UNKNOWN')
                  pkg_name = pkg.get('Name', 'unknown')

                  if license_name in prohibited_licenses:
                      violations.append(f'{pkg_name}: {license_name}')
                  elif license_name in review_required:
                      review_needed.append(f'{pkg_name}: {license_name}')
                  elif license_name == 'UNKNOWN' or not license_name:
                      unknown_licenses.append(pkg_name)

          # Create summary
          with open('license-summary.txt', 'w') as f:
              f.write(f'License Compliance Summary\n')
              f.write(f'=========================\n')
              f.write(f'License violations: {len(violations)}\n')
              f.write(f'Licenses requiring review: {len(review_needed)}\n')
              f.write(f'Unknown licenses: {len(unknown_licenses)}\n')

              if violations:
                  f.write(f'\\nVIOLATIONS:\\n')
                  for violation in violations:
                      f.write(f'  - {violation}\\n')

              if review_needed:
                  f.write(f'\\nREQUIRE REVIEW:\\n')
                  for item in review_needed:
                      f.write(f'  - {item}\\n')

              if unknown_licenses:
                  f.write(f'\\nUNKNOWN LICENSES:\\n')
                  for pkg in unknown_licenses:
                      f.write(f'  - {pkg}\\n')

              if violations:
                  f.write(f'\\nCRITICAL: License violations found!\n')
                  sys.exit(1)
          "

      - name: Upload license scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: license-scan-results
          path: |
            licenses.json
            licenses.txt
            license-summary.txt

  # Security report aggregation
  security-report:
    name: Security Report
    runs-on: ubuntu-latest
    needs: [sast-scan, dependency-scan, secrets-scan, container-scan, license-scan]
    if: always()
    steps:
      - uses: actions/checkout@v4

      - name: Download all security scan results
        uses: actions/download-artifact@v4
        with:
          path: security-results/

      - name: Generate comprehensive security report
        run: |
          python -c "
          import json
          import os
          from pathlib import Path
          from datetime import datetime

          # Aggregate all security findings
          report = {
              'scan_date': datetime.now().isoformat(),
              'repository': '${{ github.repository }}',
              'branch': '${{ github.ref_name }}',
              'commit': '${{ github.sha }}',
              'summary': {
                  'total_issues': 0,
                  'critical_issues': 0,
                  'high_issues': 0,
                  'medium_issues': 0,
                  'low_issues': 0
              },
              'scans': {}
          }

          # Process each scan type
          scan_dirs = Path('security-results').glob('*-scan-results')

          for scan_dir in scan_dirs:
              scan_type = scan_dir.name.replace('-scan-results', '')
              report['scans'][scan_type] = {}

              # Look for summary files
              summary_file = scan_dir / f'{scan_type}-summary.txt'
              if summary_file.exists():
                  with open(summary_file) as f:
                      report['scans'][scan_type]['summary'] = f.read()

          # Generate markdown report
          with open('security-report.md', 'w') as f:
              f.write('# 🔒 Security Scan Report\\n\\n')
              f.write(f'**Repository:** {report[\"repository\"]}\\n')
              f.write(f'**Branch:** {report[\"branch\"]}\\n')
              f.write(f'**Commit:** {report[\"commit\"][:8]}\\n')
              f.write(f'**Scan Date:** {report[\"scan_date\"]}\\n\\n')

              f.write('## Summary\\n\\n')
              f.write('| Scan Type | Status | Issues Found |\\n')
              f.write('|-----------|--------|--------------|\\n')

              for scan_type, data in report['scans'].items():
                  status = '✅ Pass' if 'CRITICAL' not in data.get('summary', '') else '❌ Fail'
                  f.write(f'| {scan_type.title()} | {status} | See details below |\\n')

              f.write('\\n## Detailed Results\\n\\n')

              for scan_type, data in report['scans'].items():
                  f.write(f'### {scan_type.title().replace(\"_\", \" \")} Scan\\n\\n')
                  if data.get('summary'):
                      f.write('```\\n')
                      f.write(data['summary'])
                      f.write('\\n```\\n\\n')
                  else:
                      f.write('No summary available.\\n\\n')

              f.write('## 📊 Artifacts\\n\\n')
              f.write('Detailed scan results are available in the workflow artifacts.\\n')

          print('Security report generated successfully')
          "

      - name: Check for critical security issues
        run: |
          # Check all summary files for critical issues
          critical_found=false

          for summary_file in security-results/*/; do
              if [ -f "$summary_file"*-summary.txt ]; then
                  if grep -q "CRITICAL" "$summary_file"*-summary.txt; then
                      critical_found=true
                      echo "Critical security issue found in $(basename $summary_file)"
                  fi
              fi
          done

          if [ "$critical_found" = true ]; then
              echo "critical-issues-found=true" >> $GITHUB_OUTPUT
              echo "::error::Critical security vulnerabilities detected!"
              exit 1
          else
              echo "critical-issues-found=false" >> $GITHUB_OUTPUT
              echo "No critical security issues found"
          fi

      - name: Upload comprehensive security report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: comprehensive-security-report
          path: |
            security-report.md
            security-results/

      - name: Post security report to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const report = fs.readFileSync('security-report.md', 'utf8');

              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            } catch (error) {
              console.log('Could not post security report:', error.message);

              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: '🔒 **Security Scan Completed**\n\nDetailed security scan results are available in the workflow artifacts.'
              });
            }

  # Security notification
  security-notification:
    name: Security Notifications
    runs-on: ubuntu-latest
    needs: security-report
    if: always() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    steps:
      - name: Send security alerts
        if: needs.security-report.outputs.critical-issues-found == 'true'
        run: |
          echo "Critical security vulnerabilities detected!"
          echo "Repository: ${{ github.repository }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"

          # In a real implementation, you would integrate with:
          # - Slack/Discord webhooks
          # - Email notifications
          # - Security incident management systems
          # - JIRA/GitHub Issues creation

      - name: Create security issue
        if: needs.security-report.outputs.critical-issues-found == 'true' && github.ref == 'refs/heads/main'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '🚨 Critical Security Vulnerabilities Detected',
              body: `
              Critical security vulnerabilities have been detected in the main branch.

              **Commit:** ${context.sha}
              **Workflow:** ${context.workflow}
              **Run:** ${context.runNumber}

              Please review the security scan results immediately and address any critical issues.

              See the workflow artifacts for detailed information.
              `,
              labels: ['security', 'critical', 'bug']
            });