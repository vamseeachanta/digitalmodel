# Introduction


Certification: https://simpli-web.app.link/e/oEmOrxy3lwb

The objective of search engine optimization (SEO) is to be on top of the search results and be credible. This will over time help improve the organic search in search engines.

https://lms.simplilearn.com/courses/3247/Advanced%20Search%20Engine%20Optimization%20Certification%20Program/syllabus


## How search engines work

The importance of search engine optimization is to be on top of search results and be credible. Typically the users click on top 5 results of search. Users trust search engines and search engines in turn need credible search results to drive user traffic.

Good SEO practices will help get more customers and make more sales. SEO is all about optimizing websites for search engines. SEO is an organic way to increase quantity and quality of traffic to your website. 

The search ecosystem components are:
- Users : Use internet to find information with an incentive to find most relevant information
    - About users. 
    - Search with text, images etc.. 
    - Users drive the SEO
- Search Engines : Provide relevant information through organic (and paid) search with incentive is to attract huge amount of users and generate revenue from paid search
    - Google (Dominant)
    - Yahoo!
    - Bing
    - Yandex (Russia)
    - Baidu (China) 
    - Naver (South Korea)
    - WolframAlpha
- Search Engine Optimizers: Use optimization techniques to improve organic ranking with the incentive to bring their content to the top of the search engine for users.
    - The professionals

## SEO and Social Media

With appropriate research on keywords, one can drive SEO and interlink with social media. But social media does not have direct effect but an indirect effect.

## How Search Engines work

- Google (largest reach, )
- Youtube 
- Bing
- Yahoo

Google utilized page rank. Some key attributes of a typical search engine are given below:

|  Area  | Yandex | Google | 
|--------------|-------------|------------|
| Algorithm | MatrixNet | PageRank |
| Geo Targeting | Favors Metro Areas | Favors National |
| SEO Emphasis | On-Page | Inbound Links |
| User Behavior | Major Factor | Minor Factor |
| Inbound Links | Increasing Factor | Major Factor |
| Spidering | Submit sitemaps | Agressive spidering |
| Meta-keyword influence | Yes-minor | No |

When a user searches on a search engine:
- The results are not live results.
- The results are based on search engine database. 
- Algorithm is run against this database. 
- So, a new website needs to go through 4 categories of the online mechanisms:
    - Crawling
    - Processing and indexing
    - Storing
    - Ranking
- Crawling:
    - Downloads content of the link and follows the subpages.
    - A crawler has to avoid traps
    - Crawler should not go to  protected sites. 
    - Crawler uses an "User-Agent" but others also use the same and exploit
    - Google search engine console will help assess the crawling suitability and potential problems associated
    - robots.txt ensures proper crawling and indexing of website
        - it is a protocol and not a security measure
        - Remember to put the right settings for go-live
        - Google provides a robots.txt tester
- Sitemaps
    - Representational model of the website
    - A hierarchy for users
    - xml sitemap (format)
    - helpful but not critical. Search engines prefer natural crawling
- Storing
    - Data downloaded is stored on servers of search engines
    - Search engines only access Cache
- Processing & Indexing
    - Most complex phase where algorithms work
    - Factors analyzed for indexing are inbound links, content, structure, outbound links, date etc.
    - Processing search results
        - Local search : Local results, Business listings and maps
        - COmmercial search : Retail store products
        - Entertainment search : Tickets, events, local theatre etc.
        - How-to search : Videos
- Ranking
    - Inbound links and popularity (i.e. Domain Authority) of the websites
    - Algorithm : words, content, context, type, user behavior

## Types of SEO

####  SEO Hats

- White hat
    - Stay within google webmaster guidelines
    - https://developers.google.com/search/docs/essentials
    - Take longer but robust results
- Grey hat
    - Use tips and tricks to trick the search engine
    - Illegal examples are cloaking, false redirects, hidden text and links, abusing rich snippets, scraping etc.
    - short-term benefits of higher ranks
    - Will not work in the long run
    - Keyword stuffing, SEO squatting, Automate google queries etc. Not worth the effort.
- Black hat
    - 

#### SEO Mistakes
- Using outdated techniques. 
    - Pages hidden from users. This will incur penalty and exclusion from Google
- Using wrong keywords
    - Visitors may increase but sales will fall. I.e. bounce rates and conversions
- Resisting continous learning. 

Continously invest in learning about following
- keyword research & optimization
- Analytics help learn and improve the SEO practices.
- Design principles
- User experience
- Content marketing
- Programming

#### SEO best practices

Best practices of SEO are fundamental and largely unchanged. 
- Make the website for the users
    - No hidden content (only for search engine can incur penalty)
    - stuffing words into alt text
- Optimized snippets (First impression)
    - Pulled from page title, page url and meta description tag 
    - keywords are bolded
- Prominent headings
    - Use headings to breakup contents
    - eg. H1 is used only once per page
    - eg. H2, H3 and H4 to emphasize sections of text
    - Mainly to present content in a user-friendly manner
- Well organized hierarchy
    - content and its context are important
    - A retail store may start with product i.e. Shoes and then men's, women's and kid's shoes etc.
    - if the website is not indexable, developing a redesign (or start from scratch) to develop a hierarchy becomes critical
- Practical links
    - Add context to links rather than bland links "Click Here"
    - No multiple links
- SEO spam
    - practices to promote false relevancy of the website
    - Falsifying content 
        - i.e. keyword stuffing (over optimization penalty and keyword density)
        - Doorway pages i.e. Use programming to show one page to spiders and another page to users. 
        - Hidden text (white text on white background)
        - Phishing and malicious content
    - Content duplication
    - Aggregated or scraped content: stealing content from other websites
    - Overlinking with repetitive anchor linking
    - Thin or shallow content
    - Falsifying links : Linking schemes (i.e. links by payment)
- The options for a good website: great content and legitimate marketing are the way to go

## Keyword research and competitive intelligence

- Users enter keywords to search. Keyword traffic (no of search queries) vs. competition (no of sites )
    - High keyword traffic with high compeition takes a long time
    - High keyword traffic with low compeition is ideal
    - Low keyword traffic with low compeition may also be workable
- User intent
    - Understand the intent and context is important
    - Intent
        - Lawyer vs. Attorney
        - buy vs. free (phones vs. )
- Not provided
    - Search engines provide search volume and search keywords
    - However, recently "not provided" keywords and data is not shared. Therefore, SEOs can no longer use this data to make decisions.
- Performing Keyword Research
    - Industry keywords
        - How poeple describe the product? sales, customers etc.
        - Look at other sources
    - Pay per click (PPC)
        - Get keyword information and search queries from paid search team
        - Get keywords to optimize on website
    - Internal site search
        - what keywords do users search on the site. Ideal information
    - Compeititor keywords
        - Competitor ranking and the keywords they are bidding on 
- An example approach:
    - Brand Name
        - Keywords associated with brand
        - Pages rank for brand based terms
    - Keyword concepts
        - categorize associated words
        - Group by intent and buying
    - additonal features: Time, location, feature
        - time frame, seasonality etc.
    - Questions and needs
        - Keyword association with questions
        - What and how questions
- Types of queries
    - Short tail
        - < 3 words (typically 1 or 2 words)
        - Shorter queries, higher search volume, broad intent
        - No description
        - very difficult optimize for given budgets
    - Long tail (Focus area)
        - This will make large site volume
        - >= 3 words
        - Use attributes
        - More descriptive and more targetted i.e. closer to decision
        - Longer queries, lower search volume, closer to decision intent
        - Opportunity to optimize for your business
- Competitive Analysis
    - Identify competition
    - Difficulty to beat competition
    - Content types and format (blogs, videos, etc.)
    - The analytics is still hidden from competition
    - User experience
        - Why people are linking?
        - WHy google ranked them higher?
- Competition Analysis Metrics
    - domain names
        - Keywords common in domain
    - Domain authority
        - Links and the associated domain authority
    - Number of indexed pages
        - reflects how much search engines care about the domain
    - PPC terms and advertisers
        - Ads that show for a search tells what keywords companies are willing to spend money on
- B2B vs. B2C. Fundamental practices stay the same
    - Keyword targeting and on-page optimization
    - Entertain, inform and educate

## SEO Foundations 

Includes optimizing content and html programming code. This is based on relevancy (onpage) and popularity (off-page)

### On-page Optimization

- Title tags i.e. page title
    - Not displayed on page but on the tab
    - Also shown in google search result
    - Influences click-through-rates and first brand impressions
- Meta Descriptions
    - In the code but does not influence rankings
    - Influences clicks
    - If no meta description, it will pull information from page
    - A brief explanation of content and description of page is effective
    - Search engine preference (may or may not directly influence)
- Header tags
    - Enables logical hierarchy of content
- URLs and URL structure
    - Should have at least 1 relevant word
    - Short, succint and readable
    - Domain is not primary ranking signal for search engines
    - easy to spell and pronounce
    - Mainly for marketing and branding i.e. on business cards, youtube etc.
- Image Alt Text
    - Spiders can not see images
    - alt text provides context for images
    - use these appropriately
- Internal links
    - Linking 1 page to another to define relavancy and relation
- Content : Keyword usage
    - No just instances of keyword
    - Spiders use NLP (Natural Langauge Processing)
    - Also checks the context
- Content
    - lists, bullets
    - appropraite bold text
    - etc.
- Sitemaps
    - Allows both humans (HTML) and computers (XML)
    - HTML Maps
        - Breadcrum navigation at top
        - Also at footer
- On-page Don'ts
    - keyword stuffing
        - Density was relevant before search engines utilized NLP
    - hidden text
        - Search engines look for color. Penalties may happen
        - Can negatively impact
    - repetitive anchor text
        - NLP algorithms recognize redundant and unreadable texts. Make it for humans
    - cloaking
        - Showing 1 thing to search engine and soemthing else to users
        - Can negatively impact
- Robots.txt., xml sites, https:// etc.
- slow loading pages & mobile friendlyness (more revenues for search engines)
- User behaviors
    - Brand searches
    - Direct website visits (without using search engine)
    - time on page
    - Pages per session
    - Behavior (no of clicks etc.)

### Off-page Optimization

Not on page but away from websites. Examples inlcude blog, videos, articles etc. Mainly popularity i.e. hyperlinks on the web
- Search engines highly value and consider hyperlinks 
- Difficult to influence on a day-to-day level
- Linking building is time consuming and inherently difficulty
    - External parties should have strong reason to do so

Principles of link building
- Create link worthy content
    - create content that people want to read, share and refer to in links
    - Content is key
- Offsite Engagement
    - via Social media. Also helps research needs.
    - Build relationships for long-term
- Utilize offshite relationships
    - friends, colleagues to promote new online content
    - reach to local business and agencies

- Types of Links:
    - Inbound links
    - Outbound links
-  rel="nofollow"
    - developed to combat comment spam
    - No benefit from original sites i.e. no direct benefit

- Link Building Don'ts
    - spammy links (multiple repetitive links)
    - purchasing text links is not recommended
    - Don't acquire reciprocal links. Should happen naturally
    - 1-way links are better

## Duplicate Content

- Copy content from another source and re-post
- With CMS (eg. wordpress) can run into problems when same content is seen in 2 different URLs. 
- All links should go to single page (i.e. no duplicate content)
- search cars by brand 1 page and search cars by color in another page is considered duplicate by search engines
- Fixing problems in order of preference
    - Remove the unnecessary version 
    - block by adding directories using robots.txt 
    - HTML tag, Add rel="Canonical"
    - Noindex follow means "do not index" but follow any links in the page

## Design and Architecture

For the **humans**:
- Clickable logo
- Predictable navigation (eg: top of website)
- Click worthy links (obvious to click)
- Goal-oriented design
- Multi-device friendly
For the **search engines**:
- XML sitemaps
    - place in root directory
    - also submit to search engines
    - also tells the last update of page
- Robots.txt 
    - configure
    - Use tester: https://support.google.com/webmasters/answer/6062598?hl=en
- crawler friendly media
    - videos and applications can not be accessible
    - use html5 content where possible
Key Takeaways
- Each URL should provide value as landing page for at least 1 possible search query
- Each page should be designed around a specific and actionable goal

## Local SEO

Local business can take advantage of certain aspects. Concept shifted from IP address based to exact geo-location. 
- The core is NAP (Name, Address and Phone Number)
    - Be consistent (letter for letter) in website, registration etc.
    - creates more problems
    - search all instances and fix them
- Directories
    - yelp, urbanspoon, google, tripadvisor etc.
- keywords and titles
- Domain authority
    - Popular in local search and general search
- Inbound link signals
- Reviews and citations
    - quality ( more stars)
    - quantity (> 100 reviews)
- Local search Signals
    - Schema Markup
        - search engines, devices and browsers
        - eg: click on adress will open maps; click on phone number to etc.
    - Reviews and google photos
    - User behavior

## Algorithm Updates and SEO Changes

Search engine algorithms are constantly evolving. Google changes its algorithm 500 times year. The constant fundamental is to provide high quality content.

- For detailed changes in google algorithm: https://moz.com/google-algorithm-change
- Panda : pool quality content is thrown out
- Penguin: rejected websites and domains with purchased links 
- Hummingbird: Moving away from single keyword and uses text approach (NLP).
- RankBrain is trying to make sense of new and obscure words to give context for search engines
- All this points to the constant fundamentals. Create good and marketable content

## Integrating SEO with other Disciplines

Digital marketing channels are interdependent. Optimally used in a wise manner.

- Use keyword, intend, trends and data together
- Align the messages and missions
- Analytics measures success of SEO efforts
- Utilize Yoast SEO plugin with Wordpress


## SEO Tools

The 3 types of SEO tools are:
- Search Engine Provided Tools
    - Crawler activities, page speed, critical issues, ranking, keyword performance, technical compliance
- Keyword research tools
    - analysis, competition analysis, compaign development
    - [word tracker](https://www.wordtracker.com/). Provides information on Search volume; PPC Competition; CPC (cost)
    - [keyword discovery](https://www.keyworddiscovery.com/)
    - [ubersuggest](https://neilpatel.com/ubersuggest/)
    - [spyfu](https://www.spyfu.com/)
- SEO Management tools
    - keyword research
    - link profiles
    - link analysis
    - Campaign Metric
    - COmpetitor tracking
    - COmpetitor analysis
    - historical data analysis
    - Connecting to google analytics is key to understand the trends
    - Example tools
        - [Raven SEO tool](https://raventools.com/). 7 day free trails
        - Moz
        - Majestic
        - semrush
        - Serpstat
        - linkdex

## Career Paths

- Have admin for website
- Access to social media and adds you an SEO partner
- Do your research
    - Set expectations
    - work on priorities
- Understand statistics
    - Do not overpromise
    - Educate the client on the process
- Work for an SEO company or Agency
- Develop a trusted network of skills
- Certifications
    - omcp.org
    - digitalmarketinginstitute.com
- Google.com/partners
- Google analytics academy

