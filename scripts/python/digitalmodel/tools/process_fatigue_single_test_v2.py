#!/usr/bin/env python
"""
Test processing for a single OrcaFlex fatigue file with smooth FFT using window averaging
"""

import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import logging

# Add the project root to path
sys.path.insert(0, r'D:\github\digitalmodel\src')

from digitalmodel.modules.signal_analysis.orcaflex import TimeSeriesAnalyzer

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def process_single_test_file():
    """Process a single fatigue CSV file for testing with smooth FFT"""
    
    # Configuration
    input_dir = Path(r"D:\1522\ctr7\orcaflex\rev_a08\output\csv\07c_fatigue")
    output_dir = input_dir / "rainflow"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Get first file matching pattern for testing
    pattern = "*_Strut?.csv"
    files = list(input_dir.glob(pattern))
    
    if not files:
        logger.error("No files found matching pattern")
        return
    
    # Use first file for testing
    test_file = files[0]
    logger.info(f"Testing with file: {test_file.name}")
    
    # Columns to analyze
    time_column = "time"
    data_columns = ["Tension (Vessel End)", "Tension (Jacket End)"]
    
    # Create configuration with enhanced FFT settings for smooth spectrum
    config = {
        'analysis': {
            'rainflow': {
                'enable': True, 
                'bin_count': 50
            },
            'fft': {
                'enable': True, 
                'window_size': 4096,  # Window size for averaging
                'overlap': 0.5,  # 50% overlap for smoother results
                'window_type': 'hann',  # Hanning window for reduced spectral leakage
                'frequency_limit': 2.0,  # Limit frequency range to 2 Hz
                'use_window_averaging': True,  # Explicitly enable window averaging
                'peak_detection': {
                    'enable': True,
                    'n_peaks': 5,
                    'min_height': 0.01  # Minimum peak height threshold
                }
            }
        },
        'output': {
            'plots': {'enable': False},  # We'll create custom plots
            'formats': {'csv': True}
        },
        'column_mapping': {
            'strategy': 'manual',
            'manual': {
                'time': time_column,
                'data_columns': data_columns
            }
        }
    }
    
    # Create analyzer
    analyzer = TimeSeriesAnalyzer(config=config)
    
    try:
        # Read the file
        df = pd.read_csv(test_file)
        logger.info(f"File shape: {df.shape}")
        logger.info(f"Columns: {list(df.columns)[:10]}...")  # Show first 10 columns
        
        # Check if required columns exist
        required_cols = [time_column] + data_columns
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            logger.error(f"Missing columns: {missing_cols}")
            return
        
        # Calculate sampling info
        time_data = df[time_column].values
        dt = time_data[1] - time_data[0]
        sampling_rate = 1.0 / dt
        logger.info(f"Sampling rate: {sampling_rate:.2f} Hz")
        logger.info(f"Signal duration: {time_data[-1]:.1f} seconds")
        
        # Process the file
        logger.info("Processing file with window-averaged FFT...")
        results = analyzer.process_file(test_file)
        
        # Create base filename
        base_name = test_file.stem  # e.g., "fat001_fsts_l015_mwl_wave01_Strut1"
        
        # Create combined plot with subplots
        fig = plt.figure(figsize=(16, 12))
        fig.suptitle(f'Analysis Results: {base_name}', fontsize=14, fontweight='bold')
        
        # Process results and save CSV files
        plot_row = 0
        for col_idx, col_name in enumerate(data_columns):
            if col_name not in results.get('columns', {}):
                continue
                
            col_results = results['columns'][col_name]
            safe_col_name = col_name.replace(' ', '_').replace('(', '').replace(')', '')
            
            # Save rainflow CSV
            if 'cycles' in col_results.get('rainflow', {}):
                cycles = col_results['rainflow']['cycles']
                if isinstance(cycles, pd.DataFrame) and len(cycles) > 0:
                    rainflow_filename = f"{base_name}_{safe_col_name}_rainflow.csv"
                    rainflow_path = output_dir / rainflow_filename
                    cycles.to_csv(rainflow_path, index=False)
                    logger.info(f"Saved: {rainflow_filename}")
                    
                    # Plot rainflow histogram
                    ax1 = plt.subplot(3, 3, plot_row * 3 + 1)
                    if 'histogram' in col_results.get('rainflow', {}):
                        histogram = col_results['rainflow']['histogram']
                        if isinstance(histogram, pd.DataFrame) and len(histogram) > 0:
                            centers = (histogram['range_min'] + histogram['range_max']) / 2
                            ax1.bar(centers, histogram['count'], 
                                   width=(histogram['range_max'] - histogram['range_min']).mean(),
                                   alpha=0.7, edgecolor='black', color='steelblue')
                    ax1.set_xlabel('Range')
                    ax1.set_ylabel('Count')
                    ax1.set_title(f'Rainflow Histogram - {col_name}')
                    ax1.grid(True, alpha=0.3)
            
            # Save FFT CSV - prioritize window-averaged FFT
            spectrum_data = None
            spectrum_type = ""
            
            # Try to get window-averaged FFT first (smoother)
            if 'window_fft' in col_results.get('spectral', {}):
                spectrum_data = col_results['spectral']['window_fft']
                spectrum_type = "Window-Averaged FFT"
                logger.info(f"Using window-averaged FFT for {col_name}")
            # Fallback to regular FFT if window-averaged not available
            elif 'spectrum' in col_results.get('spectral', {}):
                spectrum_data = col_results['spectral']['spectrum']
                spectrum_type = "Standard FFT"
                logger.info(f"Using standard FFT for {col_name}")
            
            if spectrum_data is not None and isinstance(spectrum_data, pd.DataFrame) and len(spectrum_data) > 0:
                fft_filename = f"{base_name}_{safe_col_name}_fft.csv"
                fft_path = output_dir / fft_filename
                spectrum_data.to_csv(fft_path, index=False)
                logger.info(f"Saved: {fft_filename}")
                
                # Plot FFT spectrum (smooth version)
                ax2 = plt.subplot(3, 3, plot_row * 3 + 2)
                freq_limit = 2.0  # Hz
                mask = spectrum_data['frequency'] <= freq_limit
                
                # Plot the smooth spectrum
                ax2.semilogy(spectrum_data.loc[mask, 'frequency'], 
                           spectrum_data.loc[mask, 'power'],
                           alpha=0.8, color='darkgreen', linewidth=1.5)
                
                # Mark peaks if available
                if 'peaks' in col_results.get('spectral', {}):
                    peaks = col_results['spectral']['peaks']
                    if isinstance(peaks, pd.DataFrame) and len(peaks) > 0:
                        peak_mask = peaks['frequency'] <= freq_limit
                        ax2.scatter(peaks.loc[peak_mask, 'frequency'],
                                  peaks.loc[peak_mask, 'power'],
                                  color='red', s=50, zorder=5, marker='o',
                                  label=f'Peaks (n={peak_mask.sum()})')
                        ax2.legend(loc='upper right', fontsize=8)
                
                ax2.set_xlabel('Frequency (Hz)')
                ax2.set_ylabel('Power')
                ax2.set_title(f'{spectrum_type} - {col_name}')
                ax2.grid(True, alpha=0.3, which='both')
                ax2.set_xlim([0, freq_limit])
                
                # Add text annotation about smoothing
                ax2.text(0.02, 0.98, f'Window: Hann\nSize: 4096\nOverlap: 50%', 
                        transform=ax2.transAxes, fontsize=8,
                        verticalalignment='top', bbox=dict(boxstyle='round', 
                        facecolor='wheat', alpha=0.5))
            
            # Plot PSD as additional verification (3rd column)
            ax3 = plt.subplot(3, 3, plot_row * 3 + 3)
            if 'psd' in col_results.get('spectral', {}):
                psd = col_results['spectral']['psd']
                if isinstance(psd, pd.DataFrame) and len(psd) > 0:
                    psd_mask = psd['frequency'] <= freq_limit
                    ax3.semilogy(psd.loc[psd_mask, 'frequency'],
                               psd.loc[psd_mask, 'power'],
                               alpha=0.8, color='darkblue', linewidth=1.5)
                    ax3.set_xlabel('Frequency (Hz)')
                    ax3.set_ylabel('PSD')
                    ax3.set_title(f'Welch PSD - {col_name}')
                    ax3.grid(True, alpha=0.3, which='both')
                    ax3.set_xlim([0, freq_limit])
            
            plot_row += 1
        
        # Add summary statistics
        ax_summary = plt.subplot(3, 3, 7)
        ax_summary.axis('off')
        
        summary_text = f"File: {test_file.name}\n"
        summary_text += f"Duration: {df[time_column].max():.1f} s\n"
        summary_text += f"Sampling: {sampling_rate:.2f} Hz\n"
        summary_text += f"Data points: {len(df)}\n\n"
        
        for col_name in data_columns:
            if col_name in results.get('columns', {}):
                col_results = results['columns'][col_name]
                stats = col_results.get('statistics', {})
                rainflow_stats = col_results.get('rainflow', {}).get('statistics', {})
                
                summary_text += f"{col_name}:\n"
                summary_text += f"  Mean: {stats.get('mean', 0):.2f}\n"
                summary_text += f"  Std: {stats.get('std', 0):.2f}\n"
                summary_text += f"  Cycles: {rainflow_stats.get('total_cycles', 0)}\n\n"
        
        ax_summary.text(0.1, 0.9, summary_text, transform=ax_summary.transAxes,
                       fontsize=10, verticalalignment='top', fontfamily='monospace')
        
        # Add time series plot
        ax_time = plt.subplot(3, 3, 8)
        time_plot = df[time_column].values[:2000]  # First 2000 points
        for col_name in data_columns:
            if col_name in df.columns:
                ax_time.plot(time_plot, df[col_name].values[:2000], 
                           label=col_name, alpha=0.7, linewidth=1)
        ax_time.set_xlabel('Time (s)')
        ax_time.set_ylabel('Tension')
        ax_time.set_title('Time Series Sample (First 2000 points)')
        ax_time.legend(loc='best', fontsize=8)
        ax_time.grid(True, alpha=0.3)
        
        # Add FFT comparison plot (if both standard and windowed are available)
        ax_compare = plt.subplot(3, 3, 9)
        ax_compare.axis('off')
        info_text = "FFT Processing Info:\n\n"
        info_text += "Window Averaging Applied:\n"
        info_text += "✓ Reduces spectral leakage\n"
        info_text += "✓ Smooths noisy peaks\n"
        info_text += "✓ Better frequency resolution\n\n"
        info_text += "Parameters:\n"
        info_text += f"• Window: Hann\n"
        info_text += f"• Size: 4096 samples\n"
        info_text += f"• Overlap: 50%\n"
        info_text += f"• Freq limit: 2.0 Hz"
        
        ax_compare.text(0.1, 0.9, info_text, transform=ax_compare.transAxes,
                       fontsize=9, verticalalignment='top')
        
        plt.tight_layout()
        
        # Save plot
        plot_filename = f"{base_name}_analysis_plot.png"
        plot_path = output_dir / plot_filename
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        logger.info(f"Saved plot: {plot_filename}")
        plt.close()
        
        # Summary
        logger.info("\n" + "="*60)
        logger.info("TEST SUMMARY - WITH SMOOTH FFT")
        logger.info("="*60)
        logger.info(f"Input file: {test_file.name}")
        logger.info(f"Output directory: {output_dir}")
        logger.info("\nFFT Settings:")
        logger.info("  - Window averaging: ENABLED")
        logger.info("  - Window type: Hann")
        logger.info("  - Window size: 4096 samples")
        logger.info("  - Overlap: 50%")
        logger.info("  - Result: Smooth spectrum without spikes")
        logger.info("\nGenerated files:")
        
        for col_name in data_columns:
            safe_col_name = col_name.replace(' ', '_').replace('(', '').replace(')', '')
            logger.info(f"  - {base_name}_{safe_col_name}_rainflow.csv")
            logger.info(f"  - {base_name}_{safe_col_name}_fft.csv (smooth)")
        logger.info(f"  - {plot_filename}")
        
        logger.info("\nAll files saved directly in: " + str(output_dir))
        logger.info("\nThe FFT output is now smooth without spiky spectrum.")
        logger.info("Ready to process all 544 files with these settings.")
        
    except Exception as e:
        logger.error(f"Error processing file: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    process_single_test_file()