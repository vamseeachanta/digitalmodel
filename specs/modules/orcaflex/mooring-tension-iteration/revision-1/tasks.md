# Tasks: OrcaFlex Mooring Tension Iteration System

> **Project Overview**  
> Phase 0 (Current Methodology Implementation): 36 hours (4.5 days)  
>   - Core Implementation: 16 hours (Tasks 0.1-0.4)  
>   - Validation Testing: 20 hours (Tasks 0.5-0.8)  
> Phase 1 MVP (Semi-Automated): 40 hours (1 week)  
> Phase 2 (Fully Automated): 68 hours (1.5 weeks additional)  
> Phase 3 (Advanced): 48 hours (1 week additional)  
> Development Approach: Progressive automation starting with manual workflow  
> **Testing Focus**: Strong validation against manual process with comprehensive test coverage

---

## Phase 0: Current Methodology Implementation (2 days)

### Task 0.1: Implement Universal OrcaFlex Runner Integration
**Objective**: Integrate with DigitalModel's universal OrcaFlex runner  
**Effort**: 4 hours  
**Priority**: Critical  
**Dependencies**: None

**Subtasks**:
- [ ] Create wrapper for `digitalmodel.modules.orcaflex.universal` module
- [ ] Implement pattern-based file selection for "fsts*125km3*pb_*.yml"
- [ ] Configure input/output directory management
- [ ] Add validation=false flag handling
- [ ] Test with actual .dat files from go-by directory

**Deliverables**:
- `UniversalRunnerWrapper` class
- Pattern matching configuration
- Directory management utilities
- Integration with existing runner

**Testing Requirements**:
- Test with fsts_l015_hwl_125km3_l100_pb_vessel_statics_6dof.dat
- Verify .sim file generation
- Validate pattern matching logic
- Ensure proper environment activation

---

### Task 0.2: Post-Processing Integration
**Objective**: Integrate with DigitalModel post-processing pipeline  
**Effort**: 4 hours  
**Priority**: Critical  
**Dependencies**: Task 0.1

**Subtasks**:
- [ ] Create wrapper for post-processing command
- [ ] Implement dm_ofx_post_fsts_lngc.yml configuration parser
- [ ] Configure parallel worker management (--workers 30)
- [ ] Extract tension data from results
- [ ] Handle CSV output format

**Deliverables**:
- `PostProcessorWrapper` class
- YAML configuration handler
- Parallel processing configuration
- CSV result parser

**Testing Requirements**:
- Test with actual .sim files from Step 1
- Verify tension extraction accuracy
- Test parallel processing with different worker counts
- Validate CSV output format

---

### Task 0.3: Tension Iteration Module
**Objective**: Implement tension adjustment based on target values  
**Effort**: 4 hours  
**Priority**: Critical  
**Dependencies**: Task 0.2

**Subtasks**:
- [ ] Parse fsts_l015_125km3_pb_target_mooring_pretension.csv
- [ ] Create wrapper for dm_ofx_anal_mooring_fsts_l015_125km3_pb.yml
- [ ] Implement tension comparison logic
- [ ] Calculate line length adjustments
- [ ] Update includefile with new properties

**Deliverables**:
- `TensionIterator` class
- Target tension parser
- Length adjustment calculator
- Includefile updater

**Testing Requirements**:
- Test with target CSV from go-by directory
- Verify tension comparison accuracy
- Test length adjustment calculations
- Validate includefile updates

---

### Task 0.4: Convergence Control System
**Objective**: Implement convergence checking and iteration control  
**Effort**: 4 hours  
**Priority**: Critical  
**Dependencies**: Task 0.3

**Subtasks**:
- [ ] Implement 5% convergence criteria check
- [ ] Monitor pretension_analysis.csv for changes
- [ ] Create iteration loop controller
- [ ] Add maximum iteration safety limit
- [ ] Implement result backup between iterations

**Deliverables**:
- `ConvergenceController` class
- Convergence criteria evaluator
- Iteration loop manager
- Result backup system

**Testing Requirements**:
- Test convergence detection with known data
- Verify 5% threshold calculation
- Test maximum iteration limits
- Validate backup system operation

**Definition of Done**:
- Full iteration cycle executes successfully
- Convergence achieved within 5% tolerance
- All commands integrated with DigitalModel
- Results match manual process output

---

### Task 0.5: Manual vs Automated Validation Testing
**Objective**: Validate automated process against manual baseline  
**Effort**: 8 hours  
**Priority**: Critical  
**Dependencies**: Tasks 0.1-0.4

**Subtasks**:
- [ ] Execute complete manual process and document results
- [ ] Record manual iteration metrics (time, iterations, tensions)
- [ ] Run automated process with identical inputs
- [ ] Compare results between manual and automated
- [ ] Validate convergence criteria enforcement
- [ ] Generate validation report

**Deliverables**:
- Manual baseline dataset
- Automated test results
- Comparison validation report
- Test execution scripts

**Manual Baseline Collection**:
```python
# Document manual process
manual_baseline = {
    'model': 'fsts_l015_hwl_125km3_l100_pb_vessel_statics_6dof.dat',
    'iterations': [],  # Record each iteration
    'timing': {
        'per_iteration': 45,  # minutes
        'total': 0
    },
    'final_tensions': {},
    'convergence_achieved': False
}
```

**Automated Validation Test**:
```python
def validate_automated_vs_manual():
    """Critical validation test comparing manual and automated results."""
    
    # Load manual baseline
    manual = load_manual_baseline()
    
    # Run automated with same config
    auto = run_automated_process(
        model=manual['model'],
        targets='fsts_l015_125km3_pb_target_mooring_pretension.csv',
        tolerance=0.05
    )
    
    # Validate results match within 1%
    for line in ['Line01', 'Line02', 'Line03', 'Line04']:
        error = abs(manual['final_tensions'][line] - auto['final_tensions'][line]) / manual['final_tensions'][line]
        assert error < 0.01, f"Tension mismatch {error:.2%}"
    
    # Validate performance improvement
    assert auto['time'] < manual['timing']['total'] * 0.1
    
    # Validate convergence
    assert auto['converged'] == True
    assert auto['max_error'] < 0.05
```

**Testing Requirements**:
- Manual process must complete first to establish baseline
- Document every manual iteration step
- Automated must match manual within Â±1%
- Performance must improve by >90%
- Convergence must be achieved with 5% tolerance

**Definition of Done**:
- Manual baseline fully documented
- Automated process validated against manual
- All assertions pass
- Validation report generated
- Ready for production certification

---

### Task 0.6: Convergence Criteria Testing
**Objective**: Validate 5% convergence tolerance enforcement  
**Effort**: 4 hours  
**Priority**: High  
**Dependencies**: Task 0.5

**Subtasks**:
- [ ] Test exact 5% convergence (boundary case)
- [ ] Test under-tolerance convergence (4%)
- [ ] Test over-tolerance non-convergence (6%)
- [ ] Test iteration limits
- [ ] Test edge cases

**Test Implementation**:
```python
def test_convergence_criteria():
    """Test convergence detection at various tolerance levels."""
    
    targets = [2500, 2500, 2500, 2500]
    
    # Test 4% - should converge
    tensions_4pct = [2600, 2600, 2400, 2400]
    assert check_convergence(tensions_4pct, targets, 0.05) == True
    
    # Test 5% - should converge (inclusive)
    tensions_5pct = [2625, 2625, 2375, 2375]
    assert check_convergence(tensions_5pct, targets, 0.05) == True
    
    # Test 6% - should NOT converge
    tensions_6pct = [2650, 2650, 2350, 2350]
    assert check_convergence(tensions_6pct, targets, 0.05) == False
```

**Deliverables**:
- Convergence test suite
- Edge case validation
- Tolerance verification report

**Definition of Done**:
- All convergence tests pass
- 5% tolerance correctly enforced
- Edge cases handled properly

---

### Task 0.7: Performance Validation Testing
**Objective**: Validate performance improvements over manual process  
**Effort**: 3 hours  
**Priority**: High  
**Dependencies**: Task 0.5

**Subtasks**:
- [ ] Measure manual process timing
- [ ] Measure automated process timing
- [ ] Calculate performance improvement
- [ ] Test batch processing performance
- [ ] Document performance metrics

**Performance Test**:
```python
def test_performance():
    """Validate >95% performance improvement."""
    
    manual_time = 3.5 * 3600  # 3.5 hours
    
    start = time.time()
    run_automated_process()
    auto_time = time.time() - start
    
    improvement = (manual_time - auto_time) / manual_time
    assert improvement > 0.95
    assert auto_time < 300  # Less than 5 minutes
```

**Deliverables**:
- Performance comparison report
- Timing metrics documentation
- Batch processing results

**Definition of Done**:
- >95% time reduction achieved
- Automated completes in <5 minutes
- Performance metrics documented

---

### Task 0.8: Integration Test Suite
**Objective**: End-to-end testing of complete iteration workflow  
**Effort**: 5 hours  
**Priority**: High  
**Dependencies**: Tasks 0.5-0.7

**Subtasks**:
- [ ] Test complete iteration workflow
- [ ] Test multiple model configurations
- [ ] Test error handling and recovery
- [ ] Test edge cases
- [ ] Create regression test baseline

**Test Matrix**:
| Configuration | Water Level | Vessel | Side | Expected |
|--------------|-------------|--------|------|----------|
| TC-01 | HWL | 125km3 | PB | Pass |
| TC-02 | MWL | 125km3 | PB | Pass |
| TC-03 | LWL | 125km3 | PB | Pass |
| TC-04 | HWL | 180km3 | PB | Pass |
| TC-05 | HWL | 125km3 | SB | Pass |

**Deliverables**:
- Complete test suite
- Test execution scripts
- Regression test baseline
- CI/CD integration

**Definition of Done**:
- All test configurations pass
- Error handling validated
- Regression baseline established
- Ready for CI/CD integration

---

## Phase 1: Semi-Automated Workflow (MVP - 1 week)

### Task 1.1: CSV Parser and Input Handler
**Objective**: Parse target tension CSVs and handle input data  
**Effort**: 6 hours  
**Priority**: High  
**Dependencies**: None

**Subtasks**:
- [ ] Create CSV parser for target tension files
- [ ] Handle optional EA values (CSV or OrcaFlex extraction)
- [ ] Parse fender properties if provided
- [ ] Validate input data completeness
- [ ] Create comprehensive test fixtures from real data

**Deliverables**:
- `CSVParser` class for tension/length targets
- Input validation framework
- Test fixtures from actual project data
- Unit test coverage >95%

**Testing Requirements**:
- Test with actual CSV files from `fsts_lngc_pretension`
- Handle malformed CSV gracefully
- Test EA extraction from both CSV and model
- Validate against known good inputs

**Definition of Done**:
- Parse all existing CSV formats correctly
- Handle missing/optional fields appropriately
- Comprehensive error messages for invalid data
- All tests passing with real data

---

### Task 1.2: OrcaFlex Runner Module
**Objective**: Execute OrcaFlex static analysis via Python API  
**Effort**: 8 hours  
**Priority**: High  
**Dependencies**: Task 1.1  

**Subtasks**:
- [ ] Create wrapper for running .yml files
- [ ] Handle .yml to .sim conversion
- [ ] Manage file paths and output locations
- [ ] Add vessel 6DOF static analysis setup
- [ ] Create mock runner for testing without license

**Deliverables**:
- `OrcaFlexRunner` class
- File management utilities
- Mock runner for testing
- Integration test suite

**Testing Requirements**:
- Test with actual `fsts*vessel_statics_6dof.yml` files
- Verify .sim file generation
- Test file path handling across platforms
- Mock tests for CI/CD without OrcaFlex

**Definition of Done**:
- Execute static analysis for all model types
- Generate .sim files in correct locations
- Handle errors gracefully with clear messages
- Mock runner enables full testing

---

### Task 1.3: Result Extractor Module
**Objective**: Post-process .sim files to extract tensions and forces  
**Effort**: 8 hours  
**Priority**: High  
**Dependencies**: Task 1.2  

**Subtasks**:
- [ ] Implement `dm_ofx_post_fsts_lngc.yml` equivalent
- [ ] Extract mooring tensions, line lengths, fender forces
- [ ] Generate CSV outputs matching current format
- [ ] Calculate tension differences from targets
- [ ] Create result validation and quality checks

**Deliverables**:
- `ResultExtractor` class
- CSV generation utilities
- Data validation framework
- Comparison reports

**Testing Requirements**:
- Test against known good .sim files
- Verify CSV format matches existing outputs
- Test extraction of all required quantities
- Validate calculations against manual checks

**Definition of Done**:
- Extract all required quantities from .sim files
- Generate CSVs matching existing format exactly
- Calculate differences accurately
- Comprehensive test coverage with real data

---

### Task 1.4: Length Calculator Module
**Objective**: Calculate new line lengths based on tension differences  
**Effort**: 10 hours  
**Priority**: High  
**Dependencies**: Task 1.3

**Subtasks**:
- [ ] Implement ÎL = L/EA Ã (T_current - T_target) calculation
- [ ] Handle major governing stiffness selection
- [ ] Generate includefile YAMLs for line lengths
- [ ] Add file overwriting with optional backup
- [ ] Create calculation validation and logging

**Deliverables**:
- `LengthCalculator` class matching `dm_ofx_anal_mooring`
- Includefile YAML generator
- Backup management system
- Calculation test suite

**Testing Requirements**:
- Test calculations against manual Excel checks
- Verify includefile format matches existing
- Test backup and restore functionality
- Validate against known convergence cases

**Definition of Done**:
- Calculate length adjustments correctly
- Generate includefiles matching existing format
- Handle file management safely
- Full test coverage with validation data

---

### Task 1.5: Convergence Reporter
**Objective**: Report iteration progress and convergence status  
**Effort**: 6 hours  
**Priority**: High  
**Dependencies**: Tasks 1.3, 1.4  

**Subtasks**:
- [ ] Create convergence checking against tolerance
- [ ] Generate iteration summary reports
- [ ] Build comparison tables (current vs target)
- [ ] Add convergence plots and visualization
- [ ] Create decision support for manual intervention

**Deliverables**:
- `ConvergenceReporter` class
- Report generation templates
- Visualization utilities
- Decision support outputs

**Testing Requirements**:
- Test convergence detection accuracy
- Verify report format and content
- Test with converging and diverging cases
- Validate decision recommendations

**Definition of Done**:
- Accurately detect convergence within tolerance
- Generate clear, actionable reports
- Provide visual convergence tracking
- Support manual go/no-go decisions

---

### Task 1.6: Integration Testing and Validation
**Objective**: End-to-end testing with real project data  
**Effort**: 8 hours  
**Priority**: High  
**Dependencies**: Tasks 1.1-1.5  

**Subtasks**:
- [ ] Create test suite using actual project files
- [ ] Validate against manual iteration results
- [ ] Test complete workflow for all vessel configurations
- [ ] Document validation results and discrepancies
- [ ] Create regression test baseline

**Deliverables**:
- Complete test suite with real data
- Validation report comparing to manual
- Test data repository structure
- CI/CD integration

**Testing Requirements**:
- Use actual files from `D:\1522\ctr7\orcaflex\rev_a08\base_files`
- Test all vessel sizes (125km3, 180km3)
- Test all water levels (hwl, mwl, lwl)
- Test all berthing sides (pb, sb)
- Validate convergence within 3-5 iterations

**Definition of Done**:
- All real project cases tested
- Results match manual process within 1%
- Test suite runs automatically
- Ready for production use

---

## Phase 2: Fully Automated Iteration (1.5 weeks)

### Task 2.1: Automatic Iteration Controller
**Objective**: Automate the complete iteration loop  
**Effort**: 12 hours  
**Priority**: High  
**Dependencies**: Phase 1 Complete

**Subtasks**:
- [ ] Implement automatic iteration loop control
- [ ] Add convergence detection and stopping criteria
- [ ] Create rollback mechanism for divergence
- [ ] Handle multiple iteration strategies
- [ ] Add progress tracking and logging

**Deliverables**:
- `IterationController` class
- Convergence management system
- Rollback functionality
- Progress tracking

**Testing Requirements**:
- Test with converging cases (3-5 iterations)
- Test with slow converging cases (8-10 iterations)
- Test divergence detection and rollback
- Validate against manual iteration counts

---

### Task 2.2: Multi-Line Jacobian Solver
**Objective**: Implement Jacobian-based optimization  
**Effort**: 16 hours  
**Priority**: High  
**Dependencies**: Task 2.1

**Subtasks**:
- [ ] Replace simple EA calculation with Jacobian
- [ ] Implement finite difference sensitivity
- [ ] Add multi-dimensional Newton-Raphson
- [ ] Handle line coupling effects
- [ ] Create adaptive step sizing

**Deliverables**:
- `JacobianSolver` class
- Sensitivity analysis framework
- Coupling effect quantification
- Performance improvements

**Testing Requirements**:
- Compare convergence speed vs simple EA
- Test with strongly coupled systems
- Validate Jacobian accuracy
- Benchmark performance improvements

---

### Task 2.3: Batch Processing System
**Objective**: Process multiple models in parallel  
**Effort**: 14 hours  
**Priority**: Medium  
**Dependencies**: Task 2.1

**Subtasks**:
- [ ] Design batch configuration format
- [ ] Implement parallel processing
- [ ] Add queue management
- [ ] Create result aggregation
- [ ] Build progress monitoring

**Deliverables**:
- Batch processing engine
- Parallel execution framework
- Result aggregation system
- Progress dashboard

**Testing Requirements**:
- Test with 10+ models simultaneously
- Verify parallel speedup
- Test failure isolation
- Validate result aggregation

---

### Task 2.4: Advanced Reporting
**Objective**: Professional reports and visualizations  
**Effort**: 12 hours  
**Priority**: Medium  
**Dependencies**: Task 2.1

**Subtasks**:
- [ ] Create report templates
- [ ] Add convergence visualization
- [ ] Build comparison analysis
- [ ] Generate Excel outputs
- [ ] Create PDF reports

**Deliverables**:
- Report generation system
- Visualization library
- Export utilities
- Template system

---

### Task 2.5: Vessel Position Optimization
**Objective**: Include vessel position in optimization  
**Effort**: 14 hours  
**Priority**: Low  
**Dependencies**: Task 2.2

**Subtasks**:
- [ ] Extract vessel 6DOF positions
- [ ] Calculate position sensitivities
- [ ] Include in optimization loop
- [ ] Validate equilibrium positions
- [ ] Test convergence improvement

**Deliverables**:
- Position optimization module
- Enhanced convergence
- Validation results

---

## Phase 3: Advanced Features (1 week)

### Task 3.1: scipy.optimize Integration
**Objective**: Use advanced optimization algorithms  
**Effort**: 12 hours  
**Priority**: Medium  
**Dependencies**: Phase 2 Complete

**Subtasks**:
- [ ] Integrate scipy.optimize solvers
- [ ] Implement trust region methods
- [ ] Add constraint handling
- [ ] Create solver selection logic
- [ ] Benchmark performance

**Deliverables**:
- scipy integration
- Multiple solver options
- Performance comparisons

---

### Task 3.2: Failure Recovery System
**Objective**: Intelligent failure handling  
**Effort**: 10 hours  
**Priority**: High  
**Dependencies**: Phase 2 Complete

**Subtasks**:
- [ ] Detect failure patterns
- [ ] Implement recovery strategies
- [ ] Add alternative starting points
- [ ] Create failure diagnostics
- [ ] Test recovery success rate

**Deliverables**:
- Failure detection system
- Recovery strategies
- Diagnostic reports

---

### Task 3.3: Production Deployment
**Objective**: Package for production use  
**Effort**: 12 hours  
**Priority**: High  
**Dependencies**: Tasks 3.1, 3.2

**Subtasks**:
- [ ] Create installation packages
- [ ] Write user documentation
- [ ] Build GUI interface
- [ ] Add license management
- [ ] Create training materials

**Deliverables**:
- Installation packages
- User documentation
- GUI application
- Training materials

---

### Task 3.4: Comprehensive Validation
**Objective**: Full validation against industry cases  
**Effort**: 14 hours  
**Priority**: High  
**Dependencies**: Task 3.3

**Subtasks**:
- [ ] Validate against published cases
- [ ] Test with extreme configurations
- [ ] Perform sensitivity analysis
- [ ] Document accuracy metrics
- [ ] Create validation report

**Deliverables**:
- Validation test suite
- Accuracy metrics
- Validation report
- Certification readiness

---

## Test Strategy and Data Management

### Test Data Repository Structure
```
tests/
âââ fixtures/
â   âââ csv_inputs/          # Real CSV files
â   âââ orcaflex_models/     # Sample .yml files
â   âââ sim_outputs/         # Known good .sim files
â   âââ expected_results/    # Validated outputs
âââ unit/                    # Unit tests per module
âââ integration/             # End-to-end tests
âââ validation/              # Comparison with manual
âââ performance/             # Benchmarking tests
```

### Test Coverage Requirements
- **Phase 1**: >95% unit test coverage
- **Phase 2**: >90% integration test coverage
- **Phase 3**: >85% overall coverage
- **Validation**: 100% of real project cases

### Continuous Testing
- Pre-commit hooks for unit tests
- CI/CD pipeline for full test suite
- Nightly validation against real data
- Performance regression testing

---

## Risk Mitigation

### Technical Risks
1. **OrcaFlex API changes**: Maintain version compatibility layer
2. **Convergence failures**: Multiple fallback strategies
3. **Performance issues**: Parallel processing and caching

### Project Risks
1. **Scope creep**: Phased approach with clear boundaries
2. **Testing complexity**: Strong mock framework
3. **User adoption**: Close collaboration with manual process users

---

## Success Metrics

### Phase 1 Success Criteria
- Semi-automated process reduces manual effort by 50%
- All test cases pass with real data
- User acceptance from current manual operators

### Phase 2 Success Criteria
- Fully automated process completes in <5 minutes
- Convergence rate >95% for typical cases
- Batch processing handles 10+ models

### Phase 3 Success Criteria
- Advanced algorithms improve convergence by 30%
- Recovery strategies handle 90% of failures
- Production deployment with <1% error rate

---

**Total Effort**: 156 hours across 3.5 weeks with strong test coverage throughout